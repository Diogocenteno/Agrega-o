{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIYdn1woOS1n"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, count, mean, max, min, variance, first, last, year, month, collect_list, collect_set, desc, avg\n",
        "\n",
        "# Inicializar a sessão Spark\n",
        "spark = SparkSession.builder.appName(\"Agregacao\").getOrCreate()\n",
        "\n",
        "# Carregar o arquivo Parquet no DataFrame 'df_video'\n",
        "df_video = spark.read.parquet(\"/content/videos-preparados.snappy.parquet\")\n",
        "\n",
        "# Exibir os primeiros registros do DataFrame\n",
        "print(\"Visualizando os primeiros registros do DataFrame:\")\n",
        "df_video.show(10)  # Exibe os primeiros 10 registros\n",
        "\n",
        "# Exibir o esquema do DataFrame\n",
        "print(\"Estrutura do DataFrame:\")\n",
        "df_video.printSchema()\n",
        "\n",
        "# Contar o número total de registros\n",
        "total_registros = df_video.count()\n",
        "print(f\"Total de registros no DataFrame: {total_registros}\")\n",
        "\n",
        "# Exibir as estatísticas básicas de todas as colunas numéricas\n",
        "print(\"Estatísticas básicas do DataFrame:\")\n",
        "df_video.describe().show()\n",
        "\n",
        "# Exibir as colunas disponíveis no DataFrame\n",
        "print(\"Colunas disponíveis no DataFrame:\")\n",
        "print(df_video.columns)\n",
        "\n",
        "# Identificar valores nulos por coluna\n",
        "print(\"Contagem de valores nulos por coluna:\")\n",
        "df_video.select([count(col(c).isNull().cast(\"int\")).alias(c) for c in df_video.columns]).show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Calcular a quantidade de registros para cada valor único da coluna \"Keyword\"\n",
        "keyword_counts = df_video.groupBy(\"Keyword\").agg(count(\"Keyword\").alias(\"Count\"))\n",
        "print(\"Quantidade de registros por Keyword:\")\n",
        "keyword_counts.show()"
      ],
      "metadata": {
        "id": "NpSy9QjMXnbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Calcular a média da coluna \"Interaction\" para cada valor único da coluna \"Keyword\"\n",
        "keyword_mean_interaction = df_video.groupBy(\"Keyword\").agg(mean(\"Interaction\").alias(\"Mean Interaction\"))\n",
        "print(\"Média de Interaction por Keyword:\")\n",
        "keyword_mean_interaction.show()"
      ],
      "metadata": {
        "id": "lyVws7pwXy75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Calcular o valor máximo da coluna \"Interaction\" para cada valor único da coluna \"Keyword\"\n",
        "# e ordenar pela nova coluna \"Rank Interactions\" em ordem decrescente\n",
        "keyword_max_interaction = df_video.groupBy(\"Keyword\").agg(max(\"Interaction\").alias(\"Rank Interactions\")).orderBy(desc(\"Rank Interactions\"))\n",
        "print(\"Máximo de Interaction por Keyword ordenado por Rank Interactions:\")\n",
        "keyword_max_interaction.show()"
      ],
      "metadata": {
        "id": "-Ue_j-Y0X6UQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Calcular a média e a variância da coluna \"Views\" para cada valor único da coluna \"Keyword\"\n",
        "keyword_views_stats = df_video.groupBy(\"Keyword\").agg(\n",
        "    mean(\"Views\").alias(\"Mean Views\"),\n",
        "    variance(\"Views\").alias(\"Variance Views\")\n",
        ")\n",
        "print(\"Média e Variância de Views por Keyword:\")\n",
        "keyword_views_stats.show()"
      ],
      "metadata": {
        "id": "MSCNgxAmYAM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Calcular a média, o valor mínimo e o valor máximo de \"Views\" para cada valor único da coluna \"Keyword\", sem casas decimais\n",
        "from pyspark.sql.functions import round\n",
        "keyword_views_summary = df_video.groupBy(\"Keyword\").agg(\n",
        "    round(mean(\"Views\")).alias(\"Mean Views\"),\n",
        "    round(min(\"Views\")).alias(\"Min Views\"),\n",
        "    round(max(\"Views\")).alias(\"Max Views\")\n",
        ")\n",
        "print(\"Resumo de Views por Keyword (Média, Mínimo, Máximo):\")\n",
        "keyword_views_summary.show()"
      ],
      "metadata": {
        "id": "SoTGNFyxYHGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Mostrar o primeiro e o último \"Published At\" para cada valor único da coluna \"Keyword\"\n",
        "keyword_published_at = df_video.groupBy(\"Keyword\").agg(\n",
        "    first(\"Published At\").alias(\"First Published At\"),\n",
        "    last(\"Published At\").alias(\"Last Published At\")\n",
        ")\n",
        "print(\"Primeiro e Último Published At por Keyword:\")\n",
        "keyword_published_at.show()"
      ],
      "metadata": {
        "id": "sYQHUOE4YOpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Contar todos os \"title\" de forma normal e todos os únicos e verificar se há diferença\n",
        "normal_title_count = df_video.select(\"title\").count()\n",
        "unique_title_count = df_video.select(\"title\").distinct().count()\n",
        "title_difference = normal_title_count != unique_title_count\n",
        "print(f\"Quantidade total de titles: {normal_title_count}\")\n",
        "print(f\"Quantidade de titles únicos: {unique_title_count}\")\n",
        "print(f\"Há diferença entre total e únicos: {title_difference}\")"
      ],
      "metadata": {
        "id": "4IKOv9kjYVTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Mostrar a quantidade de registros ordenados por ano em ordem ascendente\n",
        "records_per_year = df_video.withColumn(\"Year\", year(\"Published At\"))\\\n",
        "    .groupBy(\"Year\").count().orderBy(\"Year\")\n",
        "print(\"Quantidade de registros por Ano:\")\n",
        "records_per_year.show()"
      ],
      "metadata": {
        "id": "t0U4YW-CYaDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Mostrar a quantidade de registros ordenados por ano e mês em ordem ascendente\n",
        "records_per_year_month = df_video.withColumn(\"Year\", year(\"Published At\"))\\\n",
        "    .withColumn(\"Month\", month(\"Published At\"))\\\n",
        "    .groupBy(\"Year\", \"Month\").count().orderBy(\"Year\", \"Month\")\n",
        "print(\"Quantidade de registros por Ano e Mês:\")\n",
        "records_per_year_month.show()"
      ],
      "metadata": {
        "id": "YGP9ZPIBYept"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Calcular a média acumulativa de \"Likes\" para cada \"Keyword\" ao longo dos anos\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import sum as Fsum\n",
        "\n",
        "windowSpec = Window.partitionBy(\"Keyword\").orderBy(\"Year\").rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
        "df_with_year = df_video.withColumn(\"Year\", year(\"Published At\"))\n",
        "cumulative_likes = df_with_year.groupBy(\"Keyword\", \"Year\").agg(mean(\"Likes\").alias(\"Yearly Mean Likes\"))\\\n",
        "    .withColumn(\"Cumulative Mean Likes\", Fsum(\"Yearly Mean Likes\").over(windowSpec))\n",
        "print(\"Média acumulativa de Likes por Keyword ao longo dos anos:\")\n",
        "cumulative_likes.show()"
      ],
      "metadata": {
        "id": "Dc81JPUlYlz5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "scratchpad",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}